{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deprecated: `full_table` is just a wrapper for HathiMeta.get_fields.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from compare_tools.hathimeta import clean_description, clean_title, HathiMeta\n",
    "from compare_tools.configuration import config\n",
    "import itertools\n",
    "\n",
    "test = True\n",
    "statdir = '/data/saddl/stats/testset_stats_07_07/'\n",
    "config.update(config['test' if test else 'full'])\n",
    "meta = HathiMeta(config['metadb_path'])\n",
    "\n",
    "df = meta.full_table()\n",
    "df.description = clean_description(df.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oclc_with_multiples = \n",
    "with_desc = df[~df.description.isnull()]\n",
    "# oclc+desc matches\n",
    "swsm_counts = with_desc.groupby(['oclc_num', 'description']).htid.count().sort_index()\n",
    "multiple_swsm = swsm_counts[swsm_counts > 1].reset_index()[['oclc_num', 'description']]\n",
    "wp_dv_counts = multiple_swsm.groupby('oclc_num').description.count()\n",
    "multiple_wp_dv = wp_dv_counts[wp_dv_counts > 1].reset_index()[['oclc_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meta = pd.DataFrame([], columns=['left','right','judgment','notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21586, 5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add ground truth for SWSM\n",
    "judgments = []\n",
    "for i, s in multiple_swsm.iterrows():\n",
    "    q = \" & \".join([\"({}=='{}')\".format(k,v) for k,v in s.items()])\n",
    "    matches = with_desc.query(q)\n",
    "    try:\n",
    "        for left, right in itertools.product(matches.htid, matches.htid):\n",
    "            if left == right:\n",
    "                continue\n",
    "            judgments.append({'left':left, 'right':right, 'judgment': 'SWSM', 'notes':'oclc+desc'})\n",
    "    except:\n",
    "        print(\"Problem with \", q)\n",
    "all_meta = pd.concat([all_meta, pd.DataFrame(judgments)])\n",
    "all_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164066, 5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add ground truth for WP_DV. This will result in *some* SWSM, which will be overwritten later\n",
    "judgments = []\n",
    "for i, s in multiple_wp_dv.iterrows():\n",
    "    q = \" & \".join([\"({}=='{}')\".format(k,v) for k,v in s.items()])\n",
    "    matches = with_desc.query(q)\n",
    "    try:\n",
    "        for left, right in itertools.product(matches.htid, matches.htid):\n",
    "            if left == right:\n",
    "                continue\n",
    "            judgments.append({'left':left, 'right':right, 'judgment': 'WP_DV', 'notes':'oclc+desc'})\n",
    "    except:\n",
    "        print(\"Problem with \", q)\n",
    "all_meta = pd.concat([all_meta, pd.DataFrame(judgments)]).drop_duplicates()\n",
    "# This will sort where 'SWSM' is before 'WP_DV' - then\n",
    "# drop left/right duplicates while keeping the first ('SWSM') row\n",
    "all_meta = all_meta.sort_values(['left','right', 'judgment']).drop_duplicates(['left','right'], keep='first')\n",
    "all_meta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect 'PARTOF' and 'CONTAINS' by expanding hyphenated descriptions like 'v.1-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/strings.py:1947: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(164416, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_multivol(desc):\n",
    "    prefix, rangenum = desc.split('.')\n",
    "    start, end = [int(s) for s in rangenum.split('-')]\n",
    "    contains = [\"{}.{}\".format(prefix,i) for i in range(start, end+1)]\n",
    "    return contains\n",
    "\n",
    "multivols = df[df.description.fillna('').str.contains('^(v|c|no|pt)\\.\\d+-\\d+$')].description.value_counts().index.values\n",
    "judgments = []\n",
    "for x in multivols:\n",
    "    contains = expand_multivol(x)\n",
    "    subset = df[df.description == x][['oclc_num','htid']]\n",
    "    \n",
    "    for i, row in subset.iterrows():\n",
    "        contains_htids = df[(df.oclc_num == row.oclc_num) & df.description.isin(contains)].htid\n",
    "        for right in contains_htids:\n",
    "            judgments.append({'left':row.htid, 'right':right, 'judgment':'CONTAINS', 'notes':'desc split'})\n",
    "            judgments.append({'left':right, 'right':row.htid, 'judgment':'PARTOF', 'notes':'desc split'})\n",
    "\n",
    "all_meta = pd.concat([all_meta, pd.DataFrame(judgments)]).drop_duplicates()\n",
    "# if the v1-2 relationships were coded previously as WP_DV, drop those judgments\n",
    "# in favour of PARTOF or CONTAINS\n",
    "all_meta = all_meta.drop_duplicates(['left','right'], keep='last')\n",
    "all_meta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional judgments\n",
    "\n",
    "- Collect a sample of SWDE, where the title and author are the same, while the page count and date are different\n",
    "- Collect a sample of same AUTHOR information, where the Author is the same but the title *seems* to be different (even with fuzzy matching).\n",
    "- Collect a random sample of DIFF - where the Author is different.\n",
    "\n",
    "Title comparisons are done with a fuzzy matching, using byte-pair encoding embeddings (BPEmb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine, pdist, cdist, squareform\n",
    "bpemb_en = BPEmb(lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cleaned title to BPE encodings and keep those vectors\n",
    "title_vecs = df.title.apply(clean_title).apply(bpemb_en.encode_ids).apply(lambda x: bpemb_en.vectors[x].sum(0)).values\n",
    "title_vecs = np.vstack(title_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ground truth for 6129 authors\n",
      "300 Balfour, Clara Lucas, 1808-1878.\n",
      "RANDDIFF    13690\n",
      "AUTHOR      12761\n",
      "SWDE          242\n",
      "Name: judgment, dtype: int64\n",
      "600 Botting, Douglas.\n",
      "RANDDIFF    28010\n",
      "AUTHOR      26666\n",
      "SWDE          790\n",
      "Name: judgment, dtype: int64\n",
      "900 California. Commissioners of Transportation.\n",
      "RANDDIFF    43570\n",
      "AUTHOR      41758\n",
      "SWDE         1288\n",
      "Name: judgment, dtype: int64\n",
      "1200 Committee for Economic Development.\n",
      "RANDDIFF    56506\n",
      "AUTHOR      54067\n",
      "SWDE         1726\n",
      "Name: judgment, dtype: int64\n",
      "1500 Dick, John, 1764-1833.\n",
      "RANDDIFF    70702\n",
      "AUTHOR      67686\n",
      "SWDE         1968\n",
      "Name: judgment, dtype: int64\n",
      "1800 Federal Writers' Project. New York (City)\n",
      "RANDDIFF    84794\n",
      "AUTHOR      80764\n",
      "SWDE         2224\n",
      "Name: judgment, dtype: int64\n",
      "2100 Gill, Harjeet Singh, 1935-\n",
      "RANDDIFF    100260\n",
      "AUTHOR       95554\n",
      "SWDE          2548\n",
      "Name: judgment, dtype: int64\n",
      "2400 Harmon, Robert B. 1932-\n",
      "RANDDIFF    115032\n",
      "AUTHOR      109371\n",
      "SWDE          3980\n",
      "Name: judgment, dtype: int64\n",
      "2700 Hutchings, J. M. 1820-1902.\n",
      "RANDDIFF    128596\n",
      "AUTHOR      121783\n",
      "SWDE          4444\n",
      "Name: judgment, dtype: int64\n",
      "3000 Kavanagh, Barry F.\n",
      "RANDDIFF    142518\n",
      "AUTHOR      134556\n",
      "SWDE          4618\n",
      "Name: judgment, dtype: int64\n",
      "3300 Lewis, Henry Carvill, 1853-1888.\n",
      "RANDDIFF    155474\n",
      "AUTHOR      146603\n",
      "SWDE          4942\n",
      "Name: judgment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing ground truth for {} authors\".format(len(df.author.unique())))\n",
    "i = 0\n",
    "judgments = []\n",
    "for author, author_subset in df.sample(frac=1).groupby('author'):\n",
    "    i += 1\n",
    "    if i % 300 == 0:\n",
    "        print(i, author)\n",
    "        print(pd.DataFrame(judgments).judgment.value_counts())\n",
    "\n",
    "    # Get pairwise similarity between all titles for author\n",
    "    selection_vecs = title_vecs[author_subset.index]\n",
    "    selection_sims = squareform(pdist(selection_vecs, metric='cosine'))\n",
    "    #np.fill_diagonal(selection_sims, np.nan)\n",
    "\n",
    "    for target_i, target in enumerate(author_subset.itertuples()):\n",
    "        page_diff = author_subset.page_count.sub(target.page_count).abs()\n",
    "        date_diff = author_subset.rights_date_used.sub(target.rights_date_used).abs()\n",
    "        similar_pages = page_diff < 10\n",
    "        different_pages_lo = (page_diff > 20) & (page_diff <= 30)\n",
    "        different_pages_hi = page_diff > 30\n",
    "        different_oclc = author_subset.oclc_num != target.oclc_num\n",
    "        different_date_lo = (date_diff > 0) & (date_diff <= 10)\n",
    "        different_date_hi = (date_diff > 10)\n",
    "        same_titles = selection_sims[target_i] <= 0.1\n",
    "        same_titles[target_i] = False\n",
    "        different_titles = selection_sims[target_i] >= 0.3\n",
    "\n",
    "        # Empty if the target_desc == None, which is preferred since we're building ground truth and desc=None is unpredictable - sometimes it's the same single volume, \n",
    "        # sometimes it's not\n",
    "        same_desc = author_subset.description == target.description\n",
    "\n",
    "        # SWDE different conditions with different strictness\n",
    "        #swde = author_subset[cols][different_pages & same_titles & (different_oclc|different_date) & same_desc] # diff oclc is not reliable enough\n",
    "        for p_cond_name, page_cond in [('pages(lo)', different_pages_lo), ('pages(hi)', different_pages_hi)]:\n",
    "            for d_cond_name, date_cond in [('date(lo)', different_date_lo), ('date(hi)', different_date_hi)]:\n",
    "                swde = author_subset[page_cond & same_titles & date_cond & same_desc]\n",
    "                for htid in swde.htid:\n",
    "                    judgments.append({'left':target.htid, 'right':htid, 'judgment':'SWDE', 'notes':'fuzztitle+desc/diff:{}+{}'.format(p_cond_name, d_cond_name)})\n",
    "            \n",
    "        # AUTHOR\n",
    "        max_author = 2\n",
    "        for htid in author_subset[different_titles].htid.iloc[:max_author]:\n",
    "            judgments.append({'left':target.htid, 'right':htid, 'judgment':'AUTHOR', 'notes':'diff:fuzztitle'})\n",
    "\n",
    "    # DIFF\n",
    "    n = 2 # number of random diffs per value\n",
    "    non_author_sample = df[df.author != author_subset.iloc[0].author].sample(author_subset.shape[0]*n)\n",
    "    judgments += [{'left':left, 'right':right, 'judgment':'RANDDIFF', 'notes':'diff:author'} for left, right in zip(author_subset.htid.tolist() * n, non_author_sample.htid)]\n",
    "\n",
    "all_meta = pd.concat([all_meta, pd.DataFrame(judgments)]).drop_duplicates(['left','right'])\n",
    "del judgments\n",
    "all_meta.judgment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meta.sort_values('left').to_parquet(statdir + 'meta_gt_judgments.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RANDDIFF    287728\n",
       "AUTHOR      271388\n",
       "WP_DV       141904\n",
       "SWSM         21586\n",
       "SWDE          9930\n",
       "CONTAINS       463\n",
       "PARTOF         463\n",
       "Name: judgment, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_meta.judgment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write left/right records to json as needed by crunch_stats.py\n",
    "import json\n",
    "import pandas as pd\n",
    "all_meta = pd.read_parquet(statdir + 'meta_gt_judgments.parquet')\n",
    "with open(statdir + 'to_crunch_stats.json', mode='w') as f:\n",
    "    for row in all_meta.to_dict(orient='records'):\n",
    "        json.dump(row, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also process handcoded stats\n",
    "from htrc_features import utils\n",
    "handcoded = pd.read_csv('http://35.239.220.133/download')\n",
    "handcoded = handcoded.rename(columns={'target':'left', 'candidate':'right'})\n",
    "for col in ['left', 'right']:\n",
    "    handcoded[col] = handcoded[col].apply(utils.extract_htid)\n",
    "handcoded['notes'] = handcoded['notes'].fillna('')\n",
    "with open(statdir + 'handcoded_stats.json', mode='w') as f:\n",
    "    for row in handcoded[['left', 'right', 'judgment', 'notes']].to_dict(orient='records'):\n",
    "        json.dump(row, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating SIMDIFF judgments\n",
    "\n",
    "For this class, we look for books that are unrelated (as per author) but similar (as evidenced by a suggestion from Annoy). The only 'metadata' inference is whether the book is by the same author. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_tools.MTAnnoy import MTAnnoy\n",
    "ann = MTAnnoy(config['ann_path'], dims=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143864, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vols = meta.get_fields(['htid', 'author'])\n",
    "vols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, "
     ]
    }
   ],
   "source": [
    "import gzip, json\n",
    "max_targets = 20000\n",
    "keep_n = 10\n",
    "\n",
    "max_targets = max_targets if max_targets < len(vols) else len(vols)\n",
    "\n",
    "with gzip.open(statdir + 'simdiff_stats.json.gz', mode='w') as f:\n",
    "    for i, (ind, (htid, author)) in enumerate(vols.sample(max_targets).iterrows()):\n",
    "        # Select a volume, find the IDs of all the books by the same author,\n",
    "        # then do an ANN search and filter out same-author works\n",
    "        try:\n",
    "            same_author = meta.get_where('author == \"{}\"'.format(author), \n",
    "                                         fields=['htid'])['htid']\n",
    "            results = ann.doc_match_stats(htid, min_count=2)\n",
    "            gt = results[~results.match.isin(same_author)][['target', 'match']]\n",
    "            if gt.shape[0] > keep_n:\n",
    "                gt = gt.sample(n=keep_n)\n",
    "            gt.columns = ['left', 'right']\n",
    "            gt['judgment'] = 'SIMDIFF'\n",
    "            for record in gt.to_dict(orient='records'):\n",
    "                f.write((json.dumps(record)+'\\n').encode('utf-8'))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            print(\"Error with \", htid)\n",
    "            continue\n",
    "        if i % 250 == 0:\n",
    "            print(i, end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OCLC for ground truth\n",
    "\n",
    "Rather than loading from online, you can download beforehand with `wget -O /data/saddl/oclc_classify/{}.xml -q http://classify.oclc.org/classify2/Classify?oclc={}&summary=false`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a listing of OCLC numbers, for wgetting\n",
    "df = meta.get_fields(['htid', 'oclc_num'])\n",
    "df['oclc_num'].drop_duplicates().to_csv('unique_oclc.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse OCLC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, xmltodict, gzip\n",
    "oclc_paths = glob.glob('/data/saddl/oclc_classify/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_oclc(oclc_path, meta):\n",
    "    with open(oclc_path) as f:\n",
    "        oclc = f.read()\n",
    "    a = xmltodict.parse(oclc)['classify']\n",
    "    if a['response']['@code'] != '2':\n",
    "        return []\n",
    "\n",
    "    editions = a['editions']['edition']\n",
    "    if type(editions) is not list:\n",
    "        return []\n",
    "    metas = [(int(edition['@holdings']), edition['@oclc'], edition['@itemtype']) for edition in editions]\n",
    "    metas = sorted(metas)[::-1]\n",
    "    # Trim results to top five-most held, or drop any books with\n",
    "    # less than 20% of the top book's holding, which is less. Essentially, looking\n",
    "    # here for widely held different manifestation or expressions - hope that reduces the number of \n",
    "    # errors where a new OCLC was assigned incorrectly\n",
    "    max_holdings = metas[0][0]\n",
    "    oclc_nums = [oclc_num for holdings, oclc_num, itemtype in metas if holdings >=max_holdings*.2][:5]\n",
    "\n",
    "    # Only keep one book per oclc_num\n",
    "    diff_editions = meta[meta.oclc_num.isin(oclc_nums)].sample(frac=1).drop_duplicates('oclc_num')\n",
    "    if len(diff_editions) < 2:\n",
    "        return []\n",
    "    else:\n",
    "        permutations = [(htid1, htid2) for htid1 in diff_editions.htid for htid2 in diff_editions.htid if htid1 != htid2]\n",
    "        return permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86392"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_all_oclc_swde = []\n",
    "for i, oclc_path in enumerate(oclc_paths):\n",
    "    try:\n",
    "        results = align_oclc(oclc_path, df)\n",
    "        all_oclc_swde += results\n",
    "        break\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        print(\"Error with\", oclc_path)\n",
    "    if i % 250 == 0:\n",
    "        print(i, end=',')\n",
    "print('Done')\n",
    "len(all_oclc_swde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "oclc_gt = pd.DataFrame(all_oclc_swde, columns=['left','right'])\n",
    "oclc_gt['judgment'] = 'SWDE'\n",
    "oclc_gt['notes'] = 'oclc_classify'\n",
    "with gzip.open(statdir+'oclc_sim_stats.json.gz', mode='w') as f:\n",
    "    for record in oclc_gt.to_dict(orient='records'):\n",
    "        f.write((json.dumps(record)+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to deduplicate with the judgments from the other ground truth!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling\n",
    "\n",
    "The stats files saved to `statdir` may bear truncation. Here's how I did it during a training run:\n",
    "\n",
    "\n",
    "```\n",
    "sort -R pairwise_gr_stats.json | head -n 200000 > pairwise_gr_stats_100k-rand.json \n",
    "grep \"RANDDIFF\" to_crunch_stats.json | sort -R | head -n 50000  >to_crunch_stats_RANDDIFF_50k-rand.json \n",
    "grep \"AUTHOR\" to_crunch_stats.json | sort -R | head -n 100000  >to_crunch_stats_AUTHOR_100k-rand.json \n",
    "grep -vP \"AUTHOR|RANDDIFF\" to_crunch_stats.json | sort -R >to_crunch_stats_OTHER.json\n",
    "cat oclc_sim_stats.json pairwise_gr_stats_200k-rand.json simdiff_stats.json testset_fake_stats.json to_crunch_stats_*json | sort -R >final_crunchlist.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
