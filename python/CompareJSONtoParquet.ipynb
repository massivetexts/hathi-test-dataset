{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare JSON and Parquet EF representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htrc_features import Volume, utils\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_csv('../test_dataset_htids.csv.gz', names=['htid'])['htid']\n",
    "jsonpaths = ids.apply(lambda x: '/data/extracted-features/' + utils.id_to_rsync(x))\n",
    "parqpaths = ids.apply(lambda x: '/data/extracted-features-parquet/' + utils.id_to_rsync(x))\n",
    "parqpaths = parqpaths.str.replace('.json.bz2', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/extracted-features/uc1/pairtree_root/$b/29/69/86/$b296986/uc1.$b296986.json.bz2',\n",
       " '/data/extracted-features-parquet/uc1/pairtree_root/$b/29/69/86/$b296986/uc1.$b296986')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonpaths.iloc[0], parqpaths.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_if(path):\n",
    "    try:\n",
    "        return os.stat(path).st_size\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.98, 0.14, 32.1, 32.24)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In GB\n",
    "jsonsize = jsonpaths.apply(stat_if).div(1024**3).sum()\n",
    "metasize = (parqpaths + '.meta.json').apply(stat_if).div(1024**3).sum()\n",
    "parqsize = (parqpaths + '.tokens.parquet').apply(stat_if).div(1024**3).sum()\n",
    "jsonsize.round(2), metasize.round(2), parqsize.round(2), (metasize+parqsize).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet is larger by 134%\n"
     ]
    }
   ],
   "source": [
    "print(\"Parquet is larger by {}%\".format(int((metasize+parqsize)/jsonsize*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on token loading\n",
    "\n",
    "As you would expect, the Parquet is much quicker. Some notes, though:\n",
    "\n",
    "- the parquet option is not only reading parquet files, but their associated metadata file in JSON. It's possible to save without the metadata, but it's small enough.\n",
    "- Of course it's quicker! In addition to not needing JSON parsing and using faster decompression than BZIP2, the data has already been preprocessed and formatted into a table format.\n",
    "\n",
    "The point is that if you ever expect to read your files *more than once*, [converting your local Extracted Features collection to parquet](https://github.com/massivetexts/compare-tools/blob/master/scripts/convert-to-parquet.py) using the `Volume.save_parquet` function will save you a great deal of computing time. It is also processing that can be front-loaded - converting to Parquet can be done in the background while you're developing your project code, not at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 53s, sys: 6.33 s, total: 3min 59s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for path in jsonpaths.head(1000):\n",
    "    vol = Volume(path, parser='json')\n",
    "    tl = vol.tokenlist(pos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 528 ms, total: 20.4 s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for path in parqpaths.head(1000):\n",
    "    vol = Volume(path, parser='parquet')\n",
    "    tl = vol.tokenlist(pos=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
